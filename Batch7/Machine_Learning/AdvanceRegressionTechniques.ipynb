{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdvanceRegressionTechniques.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelaaaateng/ftw_python/blob/main/AdvanceRegressionTechniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKdeFXgnpqZX"
      },
      "source": [
        "### Regularization reduces model complexity and prevents overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCER09V9V7z7"
      },
      "source": [
        "# Ridge Regression (L2 Regularization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2RlOfDQWEVy"
      },
      "source": [
        "Use when independent variables are highly correlated (multicollinearity)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulweICyIVwSE",
        "outputId": "77c84012-4c67-4c1a-d0f3-2658fc84ddc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        " from sklearn.linear_model import Ridge\n",
        " import numpy as np\n",
        " n_samples, n_features = 10, 5\n",
        " rng = np.random.RandomState(0)\n",
        " y = rng.randn(n_samples)\n",
        " X = rng.randn(n_samples, n_features)\n",
        " clf = Ridge(alpha=1.0)\n",
        " clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "      normalize=False, random_state=None, solver='auto', tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7_nEa6yHudj"
      },
      "source": [
        "# Lasso Regression (L1 Regularization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi6KRZ7DIxkw"
      },
      "source": [
        "Works well for feature selection in case we have a huge number of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bZc0mgTV7Wd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ab9afe1b-bdd6-45cf-a32f-b789746d32a1"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "clf = Lasso(alpha=0.1)\n",
        "clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
        "Lasso(alpha=0.1)\n",
        "print(clf.coef_)\n",
        "print(clf.intercept_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.85 0.  ]\n",
            "0.15000000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0cNiD3ELAjP"
      },
      "source": [
        "# ElasticNet Regression (L1+L2 regularization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaUu4wjPLP4u"
      },
      "source": [
        "Mix of both regularization . Robust to production but to tend to have poorer metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFy2CIrzKL8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a4e4b3df-83eb-4975-ad03-666a0176c423"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.datasets import make_regression\n",
        "X, y = make_regression(n_features=2, random_state=0)\n",
        "regr = ElasticNet(random_state=0)\n",
        "regr.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
              "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
              "           random_state=0, selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6ZI5T_KNCMI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGUVIPXFNNCS"
      },
      "source": [
        "# Instance-Based Regression\n",
        "builds up a database of example data and compare new data to the database using a similarity measure in order to find the best match and make a prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xheiYDNPWeP"
      },
      "source": [
        "## k-Nearest Neighbor (kNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIb5Yk6mO0Ml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f11e0029-e600-415a-8dbb-0e5f653c68fe"
      },
      "source": [
        "X = [[0], [1], [2], [3]]\n",
        "y = [0, 0, 1, 1]\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "neigh = KNeighborsRegressor(n_neighbors=2)\n",
        "neigh.fit(X, y)\n",
        "print(neigh.predict([[1.5]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcc-XrDXPrHm"
      },
      "source": [
        "## Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg1NolwCPQGv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "69e3a20d-67c8-469d-eef5-0ab8906475b5"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "n_samples, n_features = 10, 5\n",
        "rng = np.random.RandomState(0)\n",
        "y = rng.randn(n_samples)\n",
        "X = rng.randn(n_samples, n_features)\n",
        "clf = SVR(C=1.0, epsilon=0.2)\n",
        "clf.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='scale',\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GsIqSCJQL2p"
      },
      "source": [
        "## Decision Tree Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoIQBYN3QrOv"
      },
      "source": [
        "Interpretable, robust to multicollinearity and variance.\n",
        "\n",
        "Often fast and accurate and a big favorite in machine\n",
        "learning. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rBaN5leQBKd"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdHfPsY_a1_l"
      },
      "source": [
        "# Ensemble Methods Regression\n",
        "Composed of multiple weaker models that are\n",
        "independently trained and whose predictions are\n",
        "combined in some way to make the overall prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moaXUWdvbBB2"
      },
      "source": [
        "### Random Forest\n",
        "\n",
        "uses multiple decision trees and obtain a vote from each decision tree "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRIrsthZTmnT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "093bc3bd-c4bb-46e8-c110-7a10bf24ac9d"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
        "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
        "regr.fit(X, y)\n",
        "print(regr.predict([[0, 0, 0, 0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.18146984 0.81473937 0.00145312 0.00233767]\n",
            "[-8.32987858]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcD4cHcsb-LA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJmxK2cPfsps"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV9l8TbJfuN5"
      },
      "source": [
        "### XGBoost\n",
        "Unlike Random Forest where it trains each decision tree individually. Each new model being trained in XGBoost corrects the errors made by the previous ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6w89Iy2fvV5"
      },
      "source": [
        "# import libraries\n",
        "from sklearn import datasets\n",
        "import xgboost as xgb\n",
        "\n",
        "# load date\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ_C7wTjhQLK"
      },
      "source": [
        "# split training and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eojusgsqhScF"
      },
      "source": [
        "# transform data to XGBoost specific format called DMatrix\n",
        "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
        "D_test = xgb.DMatrix(X_test, label=Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KH0QiC3hUF8"
      },
      "source": [
        "# define XGBoost model\n",
        "param = {\n",
        "    'eta': 0.3, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 3} \n",
        "\n",
        "steps = 20  # The number of training iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWs9oZKThXP8"
      },
      "source": [
        "# train model\n",
        "model = xgb.train(param, D_train, steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu1PjzN5hcTB"
      },
      "source": [
        "# test model\n",
        "preds = model.predict(D_test)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wagMtBXfiQou",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f1d2b81-de2a-4dbe-874b-d7e00710cfd9"
      },
      "source": [
        "print(best_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 0 1 2 2 2 0 2 1 2 0 2 1 2 0 0 0 1 1 0 1 0 1 0 1 0 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9gYeXagiSrv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}